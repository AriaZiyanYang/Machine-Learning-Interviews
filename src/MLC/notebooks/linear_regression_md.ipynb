{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression python multi-dimensional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression with two variables in one dimensional data\n",
    "\n",
    " \n",
    " \n",
    " $$ F(X)=X \\times W $$\n",
    " $$ C=|| F(X) - Y ||_2^2 + \\lambda ||W||_2^2$$\n",
    "\n",
    "$X_{n \\times k}$\n",
    "\n",
    "$W_{k \\times p}$\n",
    "\n",
    "$Y_{n \\times p}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient is as follows:\n",
    "$$ X^T 2 E + \\lambda 2 W$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性回归核心函数 - 使用统一的变量命名风格\n",
    "def predict(X, weights):\n",
    "    \"\"\"\n",
    "    计算线性回归的预测值\n",
    "    输入: 特征矩阵 X (n×k) 和权重矩阵 weights (k×p)\n",
    "    输出: 预测值矩阵 (n×p)\n",
    "    数学公式: y_pred = X × weights\n",
    "    \"\"\"\n",
    "    return np.matmul(X, weights)\n",
    "\n",
    "# Lambda = 0: 无正则化，可能过拟合\n",
    "# Lambda > 0: 有正则化，平衡拟合和复杂度\n",
    "# Lambda过大: 欠拟合，模型过于简单\n",
    "def ridge_loss(y_pred, y_true, weights, alpha):\n",
    "    \"\"\"\n",
    "    岭回归损失函数\n",
    "    输入: 预测值 y_pred, 真实值 y_true, 权重 weights, 正则化参数 alpha\n",
    "    输出: 总损失值\n",
    "    数学公式: C = MSE + α∑w²\n",
    "    \"\"\"\n",
    "    mse = np.mean((y_pred - y_true) ** 2)  # 均方误差\n",
    "    l2_penalty = alpha * np.sum(weights ** 2)  # L2正则化惩罚\n",
    "    return mse + l2_penalty\n",
    "\n",
    "def compute_gradient(X, y_pred, y_true, weights, alpha):\n",
    "    \"\"\"\n",
    "    计算权重更新所需的梯度\n",
    "    输入: 特征矩阵 X, 预测值 y_pred, 真实值 y_true, 权重 weights, 正则化参数 alpha\n",
    "    输出: 梯度矩阵\n",
    "    数学公式: ∇weights = Xᵀ × 2(y_pred - y_true) + α × 2weights\n",
    "    \"\"\"\n",
    "    error = y_pred - y_true  # 计算误差\n",
    "    data_gradient = 2 * np.matmul(X.T, error)  # 数据拟合梯度\n",
    "    regularization_gradient = alpha * 2 * weights  # 正则化梯度\n",
    "    return data_gradient + regularization_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y_true, weights, learning_rate, alpha, max_iterations):\n",
    "    \"\"\"\n",
    "    梯度下降训练函数\n",
    "    输入: 特征矩阵 X, 真实标签 y_true, 初始权重 weights, 学习率 learning_rate, 正则化参数 alpha, 最大迭代次数 max_iterations\n",
    "    输出: 训练后的权重 weights\n",
    "    功能: 使用梯度下降算法优化岭回归模型\n",
    "    \"\"\"\n",
    "    for i in range(max_iterations):\n",
    "        \n",
    "        y_pred = predict(X, weights)  # 计算预测值\n",
    "        loss = ridge_loss(y_pred, y_true, weights, alpha)  # 计算损失\n",
    "        gradient = compute_gradient(X, y_pred, y_true, weights, alpha)  # 计算梯度\n",
    "        weights = weights - learning_rate * gradient  # 更新权重\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"迭代 {i}: 损失 = {loss:.6f}\")  # 每100次迭代打印损失值\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take into account for the biases, we concatenate X by a 1 column, and increase the number of rows in W by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代 0: 损失 = 5.260350\n",
      "迭代 100: 损失 = 0.168555\n",
      "迭代 200: 损失 = 0.148338\n",
      "迭代 300: 损失 = 0.133698\n",
      "迭代 400: 损失 = 0.122893\n",
      "迭代 500: 损失 = 0.114794\n",
      "迭代 600: 损失 = 0.108635\n",
      "迭代 700: 损失 = 0.103885\n",
      "迭代 800: 损失 = 0.100176\n",
      "迭代 900: 损失 = 0.097245\n"
     ]
    }
   ],
   "source": [
    "# 设置数据维度参数\n",
    "n_samples, n_features, n_outputs = 100, 8, 3  # 样本数, 特征数, 输出维度\n",
    "\n",
    "# 生成随机数据\n",
    "X = np.random.random([n_samples, n_features])  # 特征矩阵 (100×8)\n",
    "weights = np.random.random([n_features, n_outputs])  # 初始权重矩阵 (8×3)\n",
    "y_true = np.random.random([n_samples, n_outputs])  # 真实标签矩阵 (100×3)\n",
    "\n",
    "# 设置训练参数\n",
    "max_iterations = 1000  # 最大迭代次数\n",
    "learning_rate = 0.0001  # 学习率\n",
    "alpha = 0.01  # L2正则化参数\n",
    "\n",
    "# 添加偏置项 (bias term)\n",
    "X = np.concatenate((X, np.ones((n_samples, 1))), axis=1)  # 在X末尾添加全1列作为偏置项\n",
    "weights = np.concatenate((weights, np.random.random((1, n_outputs))), axis=0)  # 在weights末尾添加偏置权重\n",
    "\n",
    "# 开始训练模型\n",
    "weights = fit(X, y_true, weights, learning_rate, alpha, max_iterations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclegan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
